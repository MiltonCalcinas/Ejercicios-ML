# Clasificaci√≥n de C√°ncer de Mama con √Årboles de Decisi√≥n y AdaBoost

Este ejercicio consiste en entrenar modelos de clasificaci√≥n utilizando la base de datos de **Breast Cancer Wisconsin**, con el objetivo de predecir si un tumor es maligno o benigno.

---

## üìä Variable dependiente: `diagnosis`

La variable objetivo (`diagnosis`) contiene dos clases:

- **B (Benigno)**: 62.7%
- **M (Maligno)**: 37.3%

Esto indica una distribuci√≥n moderadamente desbalanceada, por lo que se presta atenci√≥n especial a m√©tricas adicionales m√°s all√° del accuracy.

---

## üîç Desarrollo

### 1. √Årbol de Decisi√≥n

- Se entren√≥ un modelo de √°rbol de decisi√≥n ajustando el hiperpar√°metro `max_depth` mediante validaci√≥n cruzada con `GridSearchCV`.
- El mejor resultado se obtuvo con `max_depth = 4`, alcanzando un **94% de accuracy en el conjunto de test**.

### 2. Intervalo de Confianza

- Se calcul√≥ un intervalo de confianza para el `mean_test_score` de cada profundidad (`max_depth`).
- El intervalo para `max_depth = 2` inclu√≠a el mejor accuracy logrado con `max_depth = 4`, lo que sugiere que el modelo m√°s simple podr√≠a ser igualmente v√°lido.

### 3. AdaBoost

- Se entren√≥ un clasificador **AdaBoost** usando como estimador base un √°rbol de decisi√≥n con `max_depth = 2`.
- Se exploraron distintos valores para `n_estimators` mediante grid search.
- El mejor resultado se obtuvo con **20 estimadores**, logrando un **99% de accuracy en el conjunto de test**.

---

## üß™ M√©tricas del modelo AdaBoost (con `max_depth = 2`, `n_estimators = 20`)

**Accuracy en test**: `0.9941`

### üìÅ Matriz de confusi√≥n

Predicciones en columnas, reales en filas

| B  | M | X |
|----|---|---|
|108 | 0 | B |
| 1  | 62| M |




### üìÑ Classification Report

| Clase | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| B     | 0.99      | 1.00   | 1.00     | 108     |
| M     | 1.00      | 0.98   | 0.99     | 63      |

- **Accuracy global**: 99%
- **Macro promedio**: F1 = 0.99
- **Promedio ponderado**: F1 = 0.99

---

## ‚úÖ Conclusi√≥n

El uso de AdaBoost con clasificadores base simples permite mejorar significativamente el rendimiento del modelo. A pesar del uso de √°rboles de baja profundidad, se alcanz√≥ un 99% de precisi√≥n en test. Adem√°s, el an√°lisis de intervalos de confianza permiti√≥ justificar el uso de modelos m√°s simples sin p√©rdida significativa de rendimiento.
